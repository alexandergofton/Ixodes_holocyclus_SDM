---
title: "Species Distribution Model for *Ixodes holocyclus* in Eastern Australia"
author: "Alexander W. Gofton"
date: today
format:
  gfm:
    toc: true
    toc-depth: 3
  html:
    toc: true
    toc-depth: 3
    code-fold: false
    theme: cosmo
execute:
  warning: false
  message: false
  cache: false
knitr:
  opts_chunk:
    results: hold
---

# 1. Setup and Configuration

```{r setup}
# --- Core spatial ---
library(terra)
library(sf)
library(rnaturalearth)
library(rnaturalearthdata)

# --- Data manipulation ---
library(tidyverse)

# --- SDM fitting ---
library(maxnet)
library(randomForest)
library(gbm)
library(dismo)
library(mgcv)

# --- SDM evaluation and tuning ---
library(blockCV)
library(ecospat)

# --- Variable selection ---
library(corrplot)

# --- Spatial thinning ---
library(spThin)

# --- Visualisation ---
library(patchwork)
library(viridis)

# --- Set seed for reproducibility ---
set.seed(7990)

# --- Paths ---
base_dir <- "/Users/gof005/Library/CloudStorage/OneDrive-CSIRO/OneDrive - Docs/01_Projects/alpha_gal/02_SAP_2025-6/Ihol_SDM"
data_dir <- file.path(base_dir, "data")
processed_dir <- file.path(base_dir, "processed_data")
output_dir <- file.path(base_dir, "outputs")
figures_dir <- file.path(base_dir, "figures")

dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)
dir.create(figures_dir, showWarnings = FALSE, recursive = TRUE)
dir.create(processed_dir, showWarnings = FALSE, recursive = TRUE)

# --- Study area extent (Eastern Australia) ---
study_extent <- ext(140, 155, -40, -10)

# --- Australia boundary for maps ---
aus <- ne_countries(country = "Australia", scale = "medium", returnclass = "sf")
aus_states <- ne_states(country = "Australia", returnclass = "sf")
```

# 2. Occurrence Data Preparation

```{r occurrence-data}
# Load GBIF occurrence records
gbif_raw <- read_csv(file.path(data_dir, "ihol_occurrences_gbif.csv"),
                     show_col_types = FALSE)

cat("Raw GBIF records:", nrow(gbif_raw), "\n")

# Clean occurrence data
occ_clean <- gbif_raw %>%
  dplyr::select(
    id = ID, species = scientificName,
    lat = decimalLatitude, lon = decimalLongitude,
    year, month, day, state = stateProvince
  ) %>%
  filter(!is.na(lat), !is.na(lon)) %>%
  filter(lon >= 140, lon <= 155, lat >= -40, lat <= -10) %>%
  distinct(lat, lon, .keep_all = TRUE) %>%
  filter(is.na(year) | year >= 1970) %>%
  arrange(desc(year))

cat("After cleaning:", nrow(occ_clean), "unique location records\n")
cat("Year range:", min(occ_clean$year, na.rm = TRUE), "-",
    max(occ_clean$year, na.rm = TRUE), "\n")
cat("States:", paste(unique(occ_clean$state), collapse = ", "), "\n")
```

## 2.1 Spatial Thinning

```{r spatial-thinning}
thinned_file <- file.path(processed_dir, "thinned_occurrences", "thinned_data_thin1.csv")

if (file.exists(thinned_file)) {
  occ_thinned <- read_csv(thinned_file, show_col_types = FALSE)
  if ("Longitude" %in% names(occ_thinned)) {
    occ_thinned <- occ_thinned %>% rename(lon = Longitude, lat = Latitude)
  }
  cat("Loaded pre-thinned data:", nrow(occ_thinned), "records\n")
} else {
  occ_for_thinning <- occ_clean %>% mutate(species = "I_holocyclus")

  thin_dir <- file.path(processed_dir, "thinned_occurrences")
  dir.create(thin_dir, showWarnings = FALSE, recursive = TRUE)

  thinned_result <- thin(
    loc.data = occ_for_thinning,
    lat.col = "lat", long.col = "lon", spec.col = "species",
    thin.par = 10, reps = 10,
    write.files = TRUE, out.dir = thin_dir, write.log.file = FALSE
  )

  best_rep <- which.max(sapply(thinned_result, nrow))
  occ_thinned <- thinned_result[[best_rep]]
  cat("Thinned from", nrow(occ_clean), "to", nrow(occ_thinned), "records (10 km)\n")
}
```

## 2.2 Map Occurrence Points

```{r map-occurrences}
p_occ <- ggplot() +
  geom_sf(data = aus, fill = "grey90", colour = "grey40") +
  geom_sf(data = aus_states, fill = NA, colour = "grey60", linewidth = 0.3) +
  geom_point(data = occ_clean,
             aes(x = lon, y = lat),
             shape = 21, fill = "grey60", colour = "black",
             stroke = 0.3, size = 1, alpha = 1) +
  geom_point(data = occ_thinned,
             aes(x = lon, y = lat),
             shape = 21, fill = "red", colour = "black",
             stroke = 0.3, size = 1.5, alpha = 1) +
  coord_sf(xlim = c(141, 155), ylim = c(-40, -10)) +
  labs(
    title = expression(italic("Ixodes holocyclus") ~ "occurrence records"),
    subtitle = paste0("Grey: all cleaned (n=", nrow(occ_clean),
                      "), Red: spatially thinned at 10 km (n=", nrow(occ_thinned), ")"),
    x = "Longitude", y = "Latitude"
  ) +
  theme_minimal()

print(p_occ)

ggsave(file.path(figures_dir, "01_occurrence_map.png"), p_occ,
       width = 8, height = 10, dpi = 300)
```

# 3. Environmental Data Preparation

```{r load-env-data}
# --- WorldClim bioclimatic variables ---
wc_path <- file.path(data_dir, "climate_data", "climate", "wc2.1_2.5m")
bio_files <- file.path(wc_path, paste0("wc2.1_2.5m_bio_", 1:19, ".tif"))
bio_exists <- file.exists(bio_files)

if (!all(bio_exists)) {
  warning("Missing WorldClim files: ", paste(which(!bio_exists), collapse = ", "))
}

bioclim_all <- rast(bio_files[bio_exists])
names(bioclim_all) <- paste0("bio", seq_len(sum(bio_exists)))

# --- ENVIREM variables ---
envirem_path <- file.path(data_dir, "climate_data", "climate", "envirem")
envirem_files <- file.path(envirem_path, c(
  "current_2-5arcmin_annualPET.tif",
  "current_2-5arcmin_aridityIndexThornthwaite.tif",
  "current_2-5arcmin_climaticMoistureIndex.tif"
))
envirem_vars <- rast(envirem_files)
names(envirem_vars) <- c("pet_annual", "aridity_idx", "cmi_idx")

# --- CHELSA VPD ---
vpd_cache <- file.path(processed_dir, "vpd_agg_2.5arcmin.tif")

if (file.exists(vpd_cache)) {
  vpd_agg <- rast(vpd_cache)
  cat("Loaded cached VPD raster from disk\n")
} else {
  chelsa_path <- file.path(data_dir, "climate_data", "climate", "chelsa")
  vpd_files <- file.path(chelsa_path,
    paste0("CHELSA_vpd_", sprintf("%02d", 1:12), "_1981-2010_V.2.1.tif"))
  vpd_stack <- rast(vpd_files)
  vpd_stack <- vpd_stack / 100  # CHELSA VPD: Pa * 100 -> hPa
  vpd_annual <- mean(vpd_stack, na.rm = TRUE)
  names(vpd_annual) <- "vpd_annual"

  # Aggregate CHELSA from 30 arcsec to 2.5 arcmin (factor of 5)
  vpd_agg <- aggregate(vpd_annual, fact = 5, fun = "mean", na.rm = TRUE)

  writeRaster(vpd_agg, vpd_cache)
  cat("Processed and cached VPD raster to disk\n")
}

cat("Loaded:", nlyr(bioclim_all), "WorldClim +",
    nlyr(envirem_vars), "ENVIREM +", "1 CHELSA VPD layers\n")
```

## 3.1 Crop, Align, and Stack

```{r align-env-data}
# Crop all layers to study extent
bioclim_crop <- crop(bioclim_all, study_extent)

# Project to match CRS before resampling (avoids CRS mismatch warnings)
envirem_crop <- crop(envirem_vars, study_extent)
envirem_crop <- project(envirem_crop, crs(bioclim_crop))
envirem_resamp <- resample(envirem_crop, bioclim_crop[[1]], method = "bilinear")

vpd_crop <- crop(vpd_agg, study_extent)
vpd_crop <- project(vpd_crop, crs(bioclim_crop))
vpd_resamp <- resample(vpd_crop, bioclim_crop[[1]], method = "bilinear")

# Mask to land (Australia) using country boundary
aus_vect <- vect(aus)
bioclim_crop <- mask(bioclim_crop, aus_vect)
envirem_resamp <- mask(envirem_resamp, aus_vect)
vpd_resamp <- mask(vpd_resamp, aus_vect)

# Stack all environmental layers
env_all <- c(bioclim_crop, envirem_resamp, vpd_resamp)

cat("Combined environmental stack:", nlyr(env_all), "layers\n")
cat("Resolution:", res(env_all)[1], "degrees (~",
    round(res(env_all)[1] * 111, 1), "km)\n")
cat("Layers:", paste(names(env_all), collapse = ", "), "\n")
```

# 4. Variable Selection

We select variables based on ecological knowledge of *I. holocyclus* biology (Teo et al. 2021, 2024; Heath 1974) and remove multicollinear predictors.

## 4.1 Candidate Variable Selection

```{r candidate-vars}
candidate_vars <- c("bio1", "bio4", "bio5", "bio6", "bio12", "bio15",
                     "aridity_idx", "cmi_idx", "vpd_annual")

env_candidates <- env_all[[candidate_vars]]

cat("Candidate variables:", paste(candidate_vars, collapse = ", "), "\n")
```

## 4.2 Multicollinearity Check

```{r multicollinearity}
#| fig-width: 8
#| fig-height: 8

# Extract values at occurrence points for correlation analysis
occ_pts <- vect(occ_thinned, geom = c("lon", "lat"), crs = "EPSG:4326")
occ_env <- terra::extract(env_candidates, occ_pts)
occ_env <- occ_env[complete.cases(occ_env), -1]

cor_mat <- cor(occ_env, use = "pairwise.complete.obs")

corrplot(cor_mat, method = "color", type = "lower",
         addCoef.col = "black", number.cex = 0.7,
         tl.col = "black", tl.cex = 0.8,
         title = "Pairwise correlations among candidate predictors",
         mar = c(0, 0, 2, 0))

# Identify highly correlated pairs (|r| > 0.7)
high_cor <- which(abs(cor_mat) > 0.7 & upper.tri(cor_mat), arr.ind = TRUE)
if (nrow(high_cor) > 0) {
  cat("\nHighly correlated pairs (|r| > 0.7):\n")
  for (i in seq_len(nrow(high_cor))) {
    v1 <- rownames(cor_mat)[high_cor[i, 1]]
    v2 <- colnames(cor_mat)[high_cor[i, 2]]
    r <- cor_mat[high_cor[i, 1], high_cor[i, 2]]
    cat(sprintf("  %s vs %s: r = %.2f\n", v1, v2, r))
  }
}
```

## 4.3 Variable Reduction

```{r variable-reduction}
vars_to_remove <- c()

if (abs(cor_mat["bio1", "bio5"]) > 0.7 | abs(cor_mat["bio1", "bio6"]) > 0.7) {
  vars_to_remove <- c(vars_to_remove, "bio1")
  cat("Removing bio1: correlated with bio5/bio6; extremes more ecologically relevant\n")
}

if (abs(cor_mat["aridity_idx", "cmi_idx"]) > 0.7) {
  vars_to_remove <- c(vars_to_remove, "aridity_idx")
  cat("Removing aridity_idx: correlated with cmi_idx\n")
}

if (abs(cor_mat["vpd_annual", "cmi_idx"]) > 0.7) {
  vars_to_remove <- c(vars_to_remove, "cmi_idx")
  cat("Removing cmi_idx: correlated with vpd_annual; VPD is more directly relevant\n")
}

if (abs(cor_mat["bio4", "bio5"]) > 0.7 | abs(cor_mat["bio4", "bio6"]) > 0.7) {
  vars_to_remove <- c(vars_to_remove, "bio4")
  cat("Removing bio4: correlated with temperature extremes\n")
}

final_vars <- setdiff(candidate_vars, vars_to_remove)

# Second pass: remove any remaining high correlations
env_final_vals <- occ_env[, final_vars]
cor_final <- cor(env_final_vals, use = "pairwise.complete.obs")
remaining_high <- which(abs(cor_final) > 0.7 & upper.tri(cor_final), arr.ind = TRUE)

if (nrow(remaining_high) > 0) {
  cat("\nRemaining correlated pairs after first pass:\n")
  for (i in seq_len(nrow(remaining_high))) {
    v1 <- rownames(cor_final)[remaining_high[i, 1]]
    v2 <- colnames(cor_final)[remaining_high[i, 2]]
    r <- cor_final[remaining_high[i, 1], remaining_high[i, 2]]
    cat(sprintf("  %s vs %s: r = %.2f\n", v1, v2, r))
    if (v2 %in% c("cmi_idx", "aridity_idx", "bio4", "bio15")) {
      final_vars <- setdiff(final_vars, v2)
      cat(sprintf("  -> Removing %s\n", v2))
    } else if (v1 %in% c("cmi_idx", "aridity_idx", "bio4", "bio15")) {
      final_vars <- setdiff(final_vars, v1)
      cat(sprintf("  -> Removing %s\n", v1))
    }
  }
}

cat("\nFinal predictor set (", length(final_vars), "variables):",
    paste(final_vars, collapse = ", "), "\n")

env_model <- env_all[[final_vars]]
```

## 4.4 VIF Check

```{r vif-check}
occ_env_final <- occ_env[, final_vars]
occ_env_final <- occ_env_final[complete.cases(occ_env_final), ]

calc_vif <- function(df) {
  vif_vals <- numeric(ncol(df))
  names(vif_vals) <- names(df)
  for (i in seq_along(names(df))) {
    formula_str <- paste(names(df)[i], "~", paste(names(df)[-i], collapse = " + "))
    model <- lm(as.formula(formula_str), data = df)
    r2 <- summary(model)$r.squared
    vif_vals[i] <- 1 / (1 - r2)
  }
  return(vif_vals)
}

vif_values <- calc_vif(occ_env_final)
cat("VIF values:\n")
print(round(vif_values, 2))

while (max(vif_values) > 10 & length(final_vars) > 3) {
  worst <- names(which.max(vif_values))
  cat("Removing", worst, "with VIF =", round(max(vif_values), 2), "\n")
  final_vars <- setdiff(final_vars, worst)
  occ_env_final <- occ_env_final[, final_vars]
  vif_values <- calc_vif(occ_env_final)
}

cat("\nFinal variables after VIF screening (", length(final_vars), "):",
    paste(final_vars, collapse = ", "), "\n")
cat("VIF values:\n")
print(round(vif_values, 2))

env_model <- env_all[[final_vars]]
```

# 5. Background Point Generation

```{r accessible-area}
n_bg <- 10000
# Convert occurrence SpatVector to sf
occ_sf <- st_as_sf(occ_pts)

# Buffer all occurrence points by 500 km to define accessible area (M)
occ_combined <- st_union(occ_sf)
occ_projected <- st_transform(occ_combined, crs = "+proj=moll")
buffer_500km <- st_buffer(occ_projected, dist = 500000)  # 500 km in metres
buffer_wgs84 <- st_transform(buffer_500km, crs = 4326)

# Make the buffer geometry valid before intersection
buffer_wgs84 <- st_make_valid(buffer_wgs84)

# Get global land polygons and intersect with buffer to exclude ocean
world_land <- ne_countries(scale = "medium", returnclass = "sf") |>
  st_union()  # Dissolve into a single polygon

world_land <- st_make_valid(world_land)

# Use st_intersection with prepared geometries
accessible_area <- st_intersection(buffer_wgs84, world_land)

# Calculate area of the accessible region
area_km2 <- as.numeric(st_area(accessible_area)) / 1e6
```

```{r plot-accessible-area}
world_map <- ne_countries(scale = "medium", returnclass = "sf")

ggplot() +
  geom_sf(data = world_map, fill = "grey95", colour = "grey70", linewidth = 0.2) +
  geom_sf(data = accessible_area, fill = "lightblue", alpha = 0.3,
          colour = "blue", linewidth = 0.5) +
  geom_sf(data = occ_sf, colour = "red", size = 0.8, alpha = 0.6) +
  coord_sf(xlim = c(130, 155), ylim = c(-40, -10)) +
  labs(
    title = expression("Accessible area (M) for" ~ italic("Ixodes holocyclus")),
    subtitle = sprintf("500 km buffer around occurrences (land only) — %.0f km²", area_km2)
  ) +
  theme_minimal(base_size = 12)

ggsave(file.path(figures_dir, "04_accessible_area_map.png"),
       width = 12, height = 6, dpi = 300)
```

```{r Mask-environmental-rasters-to-accessible-area}
# Convert accessible area sf to a terra SpatVector for masking
accessible_vect <- vect(accessible_area)

# Crop and mask the environmental rasters to the accessible area
env_M <- crop(env_model, accessible_vect)
env_M <- mask(env_M, accessible_vect)

# Check how many valid (non-NA) cells exist within M
n_cells <- global(!is.na(env_M[[1]]), sum)[[1]]
sprintf("Valid raster cells within accessible area: %.0f", n_cells)
```

```{r background-points}
# Sample candidate background points from within the accessible area (env_M).
# Sampling directly from env_M ensures na.rm=TRUE filters to non-NA cells only,
# i.e. cells that fall within the 500 km buffered zone.
# Oversample to allow for the 5 km exclusion buffer around occurrences.
bg_sample <- spatSample(env_M, size = n_bg * 2, method = "random",
                        na.rm = TRUE, xy = TRUE)
bg_df <- data.frame(lon = bg_sample$x, lat = bg_sample$y)

# Remove background points within 5 km of any occurrence point
occ_sf_pts <- st_as_sf(occ_thinned, coords = c("lon", "lat"), crs = 4326)
bg_sf_pts <- st_as_sf(bg_df, coords = c("lon", "lat"), crs = 4326)

min_dist <- st_distance(bg_sf_pts, occ_sf_pts)
min_dist_km <- apply(min_dist, 1, min) / 1000

bg_df <- bg_df[min_dist_km > 5, ]
cat("Background points after 5 km exclusion buffer:", nrow(bg_df), "\n")

if (nrow(bg_df) > n_bg) {
  bg_df <- bg_df[sample(nrow(bg_df), n_bg), ]
}

cat("Final background points:", nrow(bg_df), "\n")
```

## 5.1 Extract Environmental Values and Build Modelling Dataset

```{r modelling-dataset}
occ_vect <- vect(occ_thinned, geom = c("lon", "lat"), crs = "EPSG:4326")
occ_env_vals <- terra::extract(env_model, occ_vect)
occ_env_vals <- data.frame(
  presence = 1,
  lon = occ_thinned$lon,
  lat = occ_thinned$lat,
  occ_env_vals[, -1]
)

bg_vect <- vect(bg_df, geom = c("lon", "lat"), crs = "EPSG:4326")
bg_env_vals <- terra::extract(env_model, bg_vect)
bg_env_vals <- data.frame(
  presence = 0,
  lon = bg_df$lon,
  lat = bg_df$lat,
  bg_env_vals[, -1]
)

model_data <- rbind(occ_env_vals, bg_env_vals)
model_data <- model_data[complete.cases(model_data), ]

cat("Modelling dataset: ", sum(model_data$presence == 1), "presences +",
    sum(model_data$presence == 0), "background =",
    nrow(model_data), "total\n")
```

## 5.2 Map Presence and Background Points

```{r map-points}
p_points <- ggplot() +
  geom_sf(data = aus, fill = "grey90", colour = "grey40") +
  geom_point(
    data = model_data %>% filter(presence == 0),
    aes(x = lon, y = lat),
    colour = "steelblue",
    fill = "steelblue",
    size = 0.3,
    alpha = 0.5,
    shape = 21
  ) +
  geom_point(
    data = model_data %>% filter(presence == 1),
    aes(x = lon, y = lat),
    shape = 21,
    fill = "red",
    colour = "black",
    stroke = 0.3,
    size = 1.5,
    alpha = 1
  ) +
  geom_sf(
    data = accessible_area,
    fill = "lightblue",
    alpha = 0.3,
    colour = NULL,
    linewidth = 0.2
  ) +
  coord_sf(xlim = c(140, 155), ylim = c(-40, -10)) +
  labs(
    title = "Modelling dataset",
    subtitle = paste0(
      "Red: presences (n=",
      sum(model_data$presence == 1),
      "), Blue: background (n=",
      sum(model_data$presence == 0),
      ")"
    ),
    x = "Longitude",
    y = "Latitude"
  ) +
  theme_minimal()

ggsave(
  file.path(figures_dir, "02_model_bg_points.png"),
  p_points,
  height = 8,
  width = 8,
  dpi = 300
)

print(p_points)
```

# 6. Spatial Cross-Validation Setup

```{r spatial-cv}
model_sf <- st_as_sf(model_data, coords = c("lon", "lat"), crs = 4326)

sb <- cv_spatial(
  x = model_sf,
  column = "presence",
  k = 5,
  size = 200000,
  selection = "random",
  iteration = 100,
  progress = FALSE
)

cat("Spatial CV folds created:\n")
for (i in 1:5) {
  n_train_pres <- sum(model_data$presence[sb$folds_list[[i]][[1]]] == 1)
  n_train_bg <- sum(model_data$presence[sb$folds_list[[i]][[1]]] == 0)
  n_test_pres <- sum(model_data$presence[sb$folds_list[[i]][[2]]] == 1)
  n_test_bg <- sum(model_data$presence[sb$folds_list[[i]][[2]]] == 0)
  cat(sprintf("  Fold %d: Train %d pres + %d bg | Test %d pres + %d bg\n",
              i, n_train_pres, n_train_bg, n_test_pres, n_test_bg))
}
```

# 7. Model Fitting and Evaluation

## 7.1 Helper Functions

```{r helper-functions}
calc_auc <- function(obs, pred) {
  n1 <- sum(obs == 1)
  n0 <- sum(obs == 0)
  if (n1 == 0 | n0 == 0) return(NA)
  ranks <- rank(pred)
  auc <- (sum(ranks[obs == 1]) - n1 * (n1 + 1) / 2) / (n1 * n0)
  return(auc)
}

calc_tss <- function(obs, pred, n_thresholds = 100) {
  thresholds <- seq(min(pred), max(pred), length.out = n_thresholds)
  tss_vals <- sapply(thresholds, function(t) {
    pred_bin <- ifelse(pred >= t, 1, 0)
    tp <- sum(pred_bin == 1 & obs == 1)
    fn <- sum(pred_bin == 0 & obs == 1)
    fp <- sum(pred_bin == 1 & obs == 0)
    tn <- sum(pred_bin == 0 & obs == 0)
    sensitivity <- tp / (tp + fn)
    specificity <- tn / (tn + fp)
    tss <- sensitivity + specificity - 1
    return(tss)
  })
  best_idx <- which.max(tss_vals)
  return(list(tss = tss_vals[best_idx], threshold = thresholds[best_idx]))
}

calc_boyce <- function(obs, pred) {
  tryCatch({
    bi <- ecospat.boyce(fit = pred, obs = pred[obs == 1],
                        nclass = 0, window.w = "default", res = 100,
                        PEplot = FALSE)
    return(bi$cor)
  }, error = function(e) return(NA))
}
```

## 7.2 Cross-Validated Model Fitting

```{r cv-model-fitting}
cv_results <- list()
pred_cols <- final_vars

for (fold_i in 1:5) {

  cat("\n=== Fold", fold_i, "===\n")

  train_idx <- sb$folds_list[[fold_i]][[1]]
  test_idx <- sb$folds_list[[fold_i]][[2]]

  train_data <- model_data[train_idx, ]
  test_data <- model_data[test_idx, ]

  train_x <- as.data.frame(train_data[, pred_cols])
  test_x <- as.data.frame(test_data[, pred_cols])
  train_y <- train_data$presence
  test_y <- test_data$presence

  # Case weights for GAM/GLM (correct prevalence bias)
  n_pres_fold <- sum(train_y == 1); n_bg_fold <- sum(train_y == 0)
  fold_wts <- ifelse(train_y == 1, n_bg_fold / n_pres_fold, 1)

  fold_results <- list()

  # --- 1. MaxEnt ---
  tryCatch({
    me_model <- maxnet(p = train_y, data = train_x,
                       maxnet.formula(p = train_y, data = train_x,
                                      classes = "lqh"))
    me_pred <- predict(me_model, test_x, type = "cloglog")
    fold_results$maxent <- list(
      auc = calc_auc(test_y, me_pred),
      tss = calc_tss(test_y, me_pred)$tss,
      boyce = calc_boyce(test_y, me_pred)
    )
    cat("  MaxEnt AUC:", round(fold_results$maxent$auc, 3), "\n")
  }, error = function(e) {
    cat("  MaxEnt failed:", e$message, "\n")
    fold_results$maxent <<- list(auc = NA, tss = NA, boyce = NA)
  })

  # --- 2. Random Forest ---
  tryCatch({
    rf_data <- cbind(presence = factor(train_y), train_x)
    rf_model <- randomForest(presence ~ ., data = rf_data,
                             ntree = 1000,
                             mtry = floor(sqrt(length(pred_cols))))
    rf_pred <- predict(rf_model, test_x, type = "prob")[, "1"]
    fold_results$rf <- list(
      auc = calc_auc(test_y, rf_pred),
      tss = calc_tss(test_y, rf_pred)$tss,
      boyce = calc_boyce(test_y, rf_pred)
    )
    cat("  Random Forest AUC:", round(fold_results$rf$auc, 3), "\n")
  }, error = function(e) {
    cat("  RF failed:", e$message, "\n")
    fold_results$rf <<- list(auc = NA, tss = NA, boyce = NA)
  })

  # --- 3. BRT ---
  tryCatch({
    brt_data <- cbind(presence = train_y, train_x)
    brt_model <- gbm.step(
      data = brt_data,
      gbm.x = which(names(brt_data) %in% pred_cols),
      gbm.y = 1,
      family = "bernoulli",
      tree.complexity = 3,
      learning.rate = 0.005,
      bag.fraction = 0.75,
      silent = TRUE,
      plot.main = FALSE
    )

    if (!is.null(brt_model)) {
      brt_pred <- predict(brt_model, test_x,
                          n.trees = brt_model$gbm.call$best.trees,
                          type = "response")
      fold_results$brt <- list(
        auc = calc_auc(test_y, brt_pred),
        tss = calc_tss(test_y, brt_pred)$tss,
        boyce = calc_boyce(test_y, brt_pred)
      )
      cat("  BRT AUC:", round(fold_results$brt$auc, 3), "\n")
    } else {
      brt_model <- gbm.step(
        data = brt_data,
        gbm.x = which(names(brt_data) %in% pred_cols),
        gbm.y = 1,
        family = "bernoulli",
        tree.complexity = 2,
        learning.rate = 0.001,
        bag.fraction = 0.75,
        silent = TRUE,
        plot.main = FALSE
      )
      if (!is.null(brt_model)) {
        brt_pred <- predict(brt_model, test_x,
                            n.trees = brt_model$gbm.call$best.trees,
                            type = "response")
        fold_results$brt <- list(
          auc = calc_auc(test_y, brt_pred),
          tss = calc_tss(test_y, brt_pred)$tss,
          boyce = calc_boyce(test_y, brt_pred)
        )
        cat("  BRT AUC:", round(fold_results$brt$auc, 3), "\n")
      } else {
        fold_results$brt <- list(auc = NA, tss = NA, boyce = NA)
        cat("  BRT: could not fit model\n")
      }
    }
  }, error = function(e) {
    cat("  BRT failed:", e$message, "\n")
    fold_results$brt <<- list(auc = NA, tss = NA, boyce = NA)
  })

  # --- 4. GAM (with case weights) ---
  tryCatch({
    gam_data <- cbind(presence = train_y, train_x)
    smooth_terms <- paste0("s(", pred_cols, ", k = 5)")
    gam_formula <- as.formula(
      paste("presence ~", paste(smooth_terms, collapse = " + "))
    )
    gam_model <- gam(gam_formula, data = gam_data,
                     family = binomial(link = "logit"),
                     weights = fold_wts,
                     method = "REML")
    gam_pred <- predict(gam_model, test_x, type = "response")
    fold_results$gam <- list(
      auc = calc_auc(test_y, gam_pred),
      tss = calc_tss(test_y, gam_pred)$tss,
      boyce = calc_boyce(test_y, gam_pred)
    )
    cat("  GAM AUC:", round(fold_results$gam$auc, 3), "\n")
  }, error = function(e) {
    cat("  GAM failed:", e$message, "\n")
    fold_results$gam <<- list(auc = NA, tss = NA, boyce = NA)
  })

  # --- 5. GLM (with case weights) ---
  tryCatch({
    glm_data <- cbind(presence = train_y, train_x)
    temp_vars <- pred_cols[grepl("bio5|bio6", pred_cols)]
    other_vars <- setdiff(pred_cols, temp_vars)
    glm_terms <- c(other_vars, paste0("poly(", temp_vars, ", 2)"))
    glm_formula <- as.formula(
      paste("presence ~", paste(glm_terms, collapse = " + "))
    )
    glm_model <- glm(glm_formula, data = glm_data,
                     family = binomial(link = "logit"),
                     weights = fold_wts)
    glm_pred <- predict(glm_model, test_x, type = "response")
    fold_results$glm <- list(
      auc = calc_auc(test_y, glm_pred),
      tss = calc_tss(test_y, glm_pred)$tss,
      boyce = calc_boyce(test_y, glm_pred)
    )
    cat("  GLM AUC:", round(fold_results$glm$auc, 3), "\n")
  }, error = function(e) {
    cat("  GLM failed:", e$message, "\n")
    fold_results$glm <<- list(auc = NA, tss = NA, boyce = NA)
  })

  cv_results[[fold_i]] <- fold_results
}
```

## 7.3 Cross-Validation Summary

```{r cv-summary}
algorithms <- c("maxent", "rf", "brt", "gam", "glm")
algo_names <- c("MaxEnt", "Random Forest", "BRT", "GAM", "GLM")

cv_summary <- data.frame(
  Algorithm = algo_names,
  AUC_mean = NA, AUC_sd = NA,
  TSS_mean = NA, TSS_sd = NA,
  Boyce_mean = NA, Boyce_sd = NA
)

for (i in seq_along(algorithms)) {
  alg <- algorithms[i]
  auc_vals <- sapply(cv_results, function(f) f[[alg]]$auc)
  tss_vals <- sapply(cv_results, function(f) f[[alg]]$tss)
  boyce_vals <- sapply(cv_results, function(f) f[[alg]]$boyce)

  cv_summary$AUC_mean[i] <- round(mean(auc_vals, na.rm = TRUE), 3)
  cv_summary$AUC_sd[i] <- round(sd(auc_vals, na.rm = TRUE), 3)
  cv_summary$TSS_mean[i] <- round(mean(tss_vals, na.rm = TRUE), 3)
  cv_summary$TSS_sd[i] <- round(sd(tss_vals, na.rm = TRUE), 3)
  cv_summary$Boyce_mean[i] <- round(mean(boyce_vals, na.rm = TRUE), 3)
  cv_summary$Boyce_sd[i] <- round(sd(boyce_vals, na.rm = TRUE), 3)
}

cat("\n========================================\n")
cat("SPATIAL CROSS-VALIDATION RESULTS (5-fold)\n")
cat("========================================\n\n")
print(cv_summary, row.names = FALSE)

write_csv(cv_summary, file.path(output_dir, "cv_performance_summary.csv"))
```

# 8. Full Model Fitting (All Data)

```{r full-model-fitting}
all_x <- as.data.frame(model_data[, pred_cols])
all_y <- model_data$presence

# Case weights for GAM/GLM (correct prevalence bias)
n_pres <- sum(all_y == 1); n_bg <- sum(all_y == 0)
case_wts <- ifelse(all_y == 1, n_bg / n_pres, 1)

full_models <- list()

# --- 1. MaxEnt ---
cat("Fitting MaxEnt on full data...\n")
full_models$maxent <- maxnet(p = all_y, data = all_x,
                             maxnet.formula(p = all_y, data = all_x,
                                            classes = "lqh"))

# --- 2. Random Forest ---
cat("Fitting Random Forest on full data...\n")
rf_full_data <- cbind(presence = factor(all_y), all_x)
full_models$rf <- randomForest(presence ~ ., data = rf_full_data,
                               ntree = 1000,
                               mtry = floor(sqrt(length(pred_cols))),
                               importance = TRUE)

# --- 3. BRT ---
cat("Fitting BRT on full data...\n")
brt_full_data <- cbind(presence = all_y, all_x)
full_models$brt <- gbm.step(
  data = brt_full_data,
  gbm.x = which(names(brt_full_data) %in% pred_cols),
  gbm.y = 1,
  family = "bernoulli",
  tree.complexity = 3,
  learning.rate = 0.005,
  bag.fraction = 0.75,
  silent = TRUE,
  plot.main = FALSE
)

if (is.null(full_models$brt)) {
  full_models$brt <- gbm.step(
    data = brt_full_data,
    gbm.x = which(names(brt_full_data) %in% pred_cols),
    gbm.y = 1,
    family = "bernoulli",
    tree.complexity = 2,
    learning.rate = 0.001,
    bag.fraction = 0.75,
    silent = TRUE,
    plot.main = FALSE
  )
}

# --- 4. GAM (with case weights) ---
cat("Fitting GAM on full data...\n")
gam_full_data <- cbind(presence = all_y, all_x)
smooth_terms <- paste0("s(", pred_cols, ", k = 5)")
gam_formula <- as.formula(
  paste("presence ~", paste(smooth_terms, collapse = " + "))
)
full_models$gam <- gam(gam_formula, data = gam_full_data,
                       family = binomial(link = "logit"),
                       weights = case_wts,
                       method = "REML")

# --- 5. GLM (with case weights) ---
cat("Fitting GLM on full data...\n")
glm_full_data <- cbind(presence = all_y, all_x)
temp_vars <- pred_cols[grepl("bio5|bio6", pred_cols)]
other_vars <- setdiff(pred_cols, temp_vars)
glm_terms <- c(other_vars, paste0("poly(", temp_vars, ", 2)"))
glm_formula <- as.formula(
  paste("presence ~", paste(glm_terms, collapse = " + "))
)
full_models$glm <- glm(glm_formula, data = glm_full_data,
                       family = binomial(link = "logit"),
                       weights = case_wts)

cat("All models fitted successfully.\n")
```

## 8.1 Variable Importance

```{r variable-importance}
#| fig-width: 10
#| fig-height: 6

rf_imp <- importance(full_models$rf, type = 2)
rf_imp_df <- data.frame(
  Variable = rownames(rf_imp),
  Importance = rf_imp[, 1],
  Algorithm = "Random Forest"
)
rf_imp_df$Importance <- rf_imp_df$Importance / max(rf_imp_df$Importance) * 100

if (!is.null(full_models$brt)) {
  brt_imp <- summary(full_models$brt, plotit = FALSE)
  brt_imp_df <- data.frame(
    Variable = brt_imp$var,
    Importance = brt_imp$rel.inf,
    Algorithm = "BRT"
  )
}

var_imp_all <- bind_rows(rf_imp_df, brt_imp_df)

p_varimp <- ggplot(var_imp_all, aes(x = reorder(Variable, Importance),
                                     y = Importance, fill = Algorithm)) +
  geom_col(position = "dodge") +
  coord_flip() +
  labs(title = "Variable importance across algorithms",
       x = "", y = "Relative importance (%)") +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal() +
  theme(legend.position = "top")

print(p_varimp)

ggsave(file.path(figures_dir, "02_variable_importance.png"), p_varimp,
       width = 10, height = 6, dpi = 300)
```

## 8.2 Response Curves

```{r response-curves}
#| fig-width: 12
#| fig-height: 8

# Use occurrence-point medians as baseline (not full-data means,
# which are dominated by background in unsuitable areas)
occ_x <- all_x[all_y == 1, ]
occ_medians <- apply(occ_x, 2, median, na.rm = TRUE)

response_plots <- list()

for (var in pred_cols) {
  var_range <- seq(
    min(all_x[[var]], na.rm = TRUE),
    max(all_x[[var]], na.rm = TRUE),
    length.out = 200
  )

  pred_data <- as.data.frame(
    matrix(rep(occ_medians, each = 200),
           nrow = 200, dimnames = list(NULL, pred_cols))
  )
  pred_data[[var]] <- var_range

  gam_response <- predict(full_models$gam, pred_data, type = "response")

  response_df <- data.frame(x = var_range, y = gam_response)

  occ_subset <- occ_env_vals[occ_env_vals[["presence"]] == 1, ]
  occ_range <- range(occ_subset[[var]], na.rm = TRUE)

  response_plots[[var]] <- ggplot(response_df, aes(x = x, y = y)) +
    geom_line(colour = "darkblue", linewidth = 1) +
    geom_vline(xintercept = occ_range, linetype = "dashed", colour = "red",
               alpha = 0.5) +
    labs(title = var, x = var, y = "Predicted suitability") +
    ylim(0, 1) +
    theme_minimal() +
    theme(plot.title = element_text(size = 10))
}

p_response <- wrap_plots(response_plots, ncol = 3) +
  plot_annotation(
    title = "GAM response curves",
    subtitle = "Red dashed lines = observed range at occurrence points"
  )

print(p_response)

ggsave(file.path(figures_dir, "03_response_curves.png"), p_response,
       width = 12, height = 8, dpi = 300)
```

# 9. Ensemble Prediction

```{r ensemble-prediction}
cat("Extracting raster values for prediction...\n")

env_df <- as.data.frame(env_model, xy = TRUE, cells = TRUE, na.rm = TRUE)
pred_df <- env_df[, final_vars]

# Helper: write predictions back into a raster template
fill_raster <- function(template, cells, vals, name) {
  r <- init(template[[1]], fun = NA)
  v <- as.matrix(values(r))
  v[cells, 1] <- as.numeric(vals)
  values(r) <- v
  names(r) <- name
  r
}

# --- MaxEnt ---
cat("  Predicting MaxEnt...\n")
me_pred_vals <- predict(full_models$maxent, pred_df, type = "cloglog")
pred_maxent <- fill_raster(env_model, env_df$cell, me_pred_vals, "maxent")

# --- Random Forest ---
cat("  Predicting Random Forest...\n")
rf_pred_vals <- predict(full_models$rf, pred_df, type = "prob")[, "1"]
pred_rf <- fill_raster(env_model, env_df$cell, rf_pred_vals, "rf")

# --- BRT ---
cat("  Predicting BRT...\n")
if (!is.null(full_models$brt)) {
  brt_pred_vals <- predict(full_models$brt, pred_df,
                           n.trees = full_models$brt$gbm.call$best.trees,
                           type = "response")
  pred_brt <- fill_raster(env_model, env_df$cell, brt_pred_vals, "brt")
} else {
  cat("  WARNING: BRT model was NULL; using placeholder\n")
  pred_brt <- NULL
}

# --- GAM ---
cat("  Predicting GAM...\n")
gam_pred_vals <- predict(full_models$gam, pred_df, type = "response")
pred_gam <- fill_raster(env_model, env_df$cell, gam_pred_vals, "gam")

# --- GLM ---
cat("  Predicting GLM...\n")
glm_pred_vals <- predict(full_models$glm, pred_df, type = "response")
pred_glm <- fill_raster(env_model, env_df$cell, glm_pred_vals, "glm")

cat("Individual model predictions generated.\n")
```

## 9.1 AUC-Weighted Ensemble

```{r ensemble-weights}
weights <- cv_summary$AUC_mean
names(weights) <- algorithms

weights <- weights / sum(weights, na.rm = TRUE)
weights[is.na(weights)] <- 0

cat("Ensemble weights (proportional to CV AUC):\n")
for (i in seq_along(algo_names)) {
  cat(sprintf("  %s: %.3f (AUC = %.3f)\n",
              algo_names[i], weights[i], cv_summary$AUC_mean[i]))
}

pred_list <- list(maxent = pred_maxent, rf = pred_rf, gam = pred_gam, glm = pred_glm)
weight_list <- weights[c("maxent", "rf", "gam", "glm")]

if (!is.null(pred_brt)) {
  pred_list$brt <- pred_brt
  weight_list <- c(weight_list, weights["brt"])
}

weight_list <- weight_list / sum(weight_list, na.rm = TRUE)

ensemble_mean <- pred_list[[1]] * 0
for (nm in names(pred_list)) {
  ensemble_mean <- ensemble_mean + pred_list[[nm]] * weight_list[nm]
}
names(ensemble_mean) <- "ensemble_suitability"

pred_stack <- rast(pred_list)
ensemble_sd <- app(pred_stack, fun = "sd", na.rm = TRUE)
names(ensemble_sd) <- "ensemble_uncertainty"

cat("Ensemble prediction generated.\n")
cat("Suitability range:", round(global(ensemble_mean, "min", na.rm = TRUE)[[1]], 3),
    "to", round(global(ensemble_mean, "max", na.rm = TRUE)[[1]], 3), "\n")
```

## 9.2 Binary Threshold Map

```{r binary-map}
full_pred_at_points <- terra::extract(ensemble_mean, occ_vect)$ensemble_suitability
full_pred_at_bg <- terra::extract(ensemble_mean, bg_vect)$ensemble_suitability

full_preds <- c(full_pred_at_points, full_pred_at_bg)
full_obs <- c(rep(1, length(full_pred_at_points)), rep(0, length(full_pred_at_bg)))

valid <- complete.cases(full_preds, full_obs)
tss_result <- calc_tss(full_obs[valid], full_preds[valid])

cat("Optimal TSS threshold:", round(tss_result$threshold, 3), "\n")
cat("TSS at threshold:", round(tss_result$tss, 3), "\n")

ensemble_binary <- ensemble_mean >= tss_result$threshold
names(ensemble_binary) <- "predicted_presence"

cell_areas <- cellSize(ensemble_binary, unit = "km")
suitable_area <- global(ensemble_binary * cell_areas, "sum", na.rm = TRUE)[[1]]
cat("Predicted suitable area:", format(round(suitable_area), big.mark = ","), "km2\n")
```

# 10. Visualisation and Output

## 10.1 Ensemble Suitability Map

```{r map-ensemble}
#| fig-width: 10
#| fig-height: 10

ensemble_df <- as.data.frame(ensemble_mean, xy = TRUE, na.rm = TRUE)
names(ensemble_df) <- c("x", "y", "suitability")

p_ensemble <- ggplot() +
  geom_raster(data = ensemble_df, aes(x = x, y = y, fill = suitability)) +
  geom_sf(data = aus, fill = NA, colour = "black", linewidth = 0.3) +
  geom_point(data = occ_thinned, aes(x = lon, y = lat),
             colour = "red", size = 0.8, alpha = 0.5, shape = 16) +
  scale_fill_viridis(option = "magma", direction = -1,
                     name = "Habitat\nSuitability",
                     limits = c(0, 1)) +
  coord_sf(xlim = c(140, 155), ylim = c(-40, -10)) +
  labs(
    title = expression("Ensemble habitat suitability for" ~ italic("Ixodes holocyclus")),
    subtitle = "AUC-weighted mean of MaxEnt, RF, BRT, GAM, GLM",
    x = "Longitude", y = "Latitude"
  ) +
  theme_minimal() +
  theme(legend.position = "right")

print(p_ensemble)

ggsave(file.path(figures_dir, "04_ensemble_suitability.png"), p_ensemble,
       width = 10, height = 10, dpi = 300)
```

## 10.2 Binary Presence Map

```{r map-binary}
#| fig-width: 10
#| fig-height: 10

binary_df <- as.data.frame(ensemble_binary, xy = TRUE, na.rm = TRUE)
names(binary_df) <- c("x", "y", "presence")
binary_df$presence <- factor(as.integer(binary_df$presence),
                             levels = c(0L, 1L),
                             labels = c("Unsuitable", "Suitable"))

p_binary <- ggplot() +
  geom_sf(data = aus, fill = NA, colour = "black", linewidth = 0.3) +
  geom_raster(data = binary_df,
              aes(x = x, y = y, fill = presence)) +
  geom_point(data = occ_thinned, aes(x = lon, y = lat),
             colour = "red", size = 0.8, alpha = 0.8, shape = 16) +
  scale_fill_manual(values = c("Unsuitable" = "grey60", "Suitable" = "lightblue"),
                    name = "") +
  coord_sf(xlim = c(140, 155), ylim = c(-40, -10)) +
  labs(
    title = expression("Predicted distribution of" ~ italic("Ixodes holocyclus")),
    subtitle = paste0("TSS-optimised threshold = ", round(tss_result$threshold, 3),
                      " | Red dots = occurrence records"),
    x = "Longitude", y = "Latitude"
  ) +
  theme_minimal() +
  theme(legend.position = "right")

print(p_binary)

ggsave(file.path(figures_dir, "05_binary_distribution.png"), p_binary,
       width = 10, height = 10, dpi = 300)
```

## 10.3 Prediction Uncertainty Map

```{r map-uncertainty}
#| fig-width: 10
#| fig-height: 10

uncert_df <- as.data.frame(ensemble_sd, xy = TRUE, na.rm = TRUE)
names(uncert_df) <- c("x", "y", "uncertainty")

p_uncert <- ggplot() +
  geom_raster(data = uncert_df,
              aes(x = x, y = y, fill = uncertainty)) +
  geom_sf(data = aus, fill = NA, colour = "black", linewidth = 0.3) +
  scale_fill_viridis(option = "plasma", name = "SD across\nmodels") +
  coord_sf(xlim = c(140, 155), ylim = c(-40, -10)) +
  labs(
    title = "Prediction uncertainty",
    subtitle = "Standard deviation across 5 SDM algorithms",
    x = "Longitude", y = "Latitude"
  ) +
  theme_minimal() +
  theme(legend.position = "right")

print(p_uncert)

ggsave(file.path(figures_dir, "06_prediction_uncertainty.png"), p_uncert,
       width = 10, height = 10, dpi = 300)
```

## 10.4 Individual Model Comparison

```{r map-individual-models}
#| fig-width: 14
#| fig-height: 10

make_pred_df <- function(rast, name) {
  df <- as.data.frame(rast, xy = TRUE, na.rm = TRUE)
  names(df) <- c("x", "y", "suitability")
  df$model <- name
  return(df)
}

pred_dfs <- list(
  make_pred_df(pred_maxent, "MaxEnt"),
  make_pred_df(pred_rf, "Random Forest"),
  make_pred_df(pred_gam, "GAM"),
  make_pred_df(pred_glm, "GLM"),
  make_pred_df(ensemble_mean, "Ensemble")
)
if (!is.null(pred_brt)) {
  pred_dfs <- c(pred_dfs, list(make_pred_df(pred_brt, "BRT")))
}
all_pred_df <- bind_rows(pred_dfs)

p_compare <- ggplot() +
  geom_raster(data = all_pred_df,
              aes(x = x, y = y, fill = suitability)) +
  geom_sf(data = aus, fill = NA, colour = "black", linewidth = 0.2) +
  scale_fill_viridis(option = "magma", direction = -1,
                     name = "Suitability", limits = c(0, 1)) +
  coord_sf(xlim = c(140, 155), ylim = c(-40, -10)) +
  facet_wrap(~model, ncol = 3) +
  labs(
    title = expression("Individual model predictions for" ~ italic("Ixodes holocyclus")),
    x = "Longitude", y = "Latitude"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom",
        strip.text = element_text(size = 12, face = "bold"))

print(p_compare)

ggsave(file.path(figures_dir, "07_model_comparison.png"), p_compare,
       width = 14, height = 10, dpi = 300)
```

## 10.5 Save GeoTIFF Outputs

```{r save-outputs}
sdm_output_dir <- file.path(output_dir, "sdm_results")
dir.create(sdm_output_dir, showWarnings = FALSE, recursive = TRUE)

writeRaster(ensemble_mean,
            file.path(sdm_output_dir, "ensemble_suitability.tif"),
            overwrite = TRUE)
writeRaster(ensemble_sd,
            file.path(sdm_output_dir, "ensemble_uncertainty.tif"),
            overwrite = TRUE)
writeRaster(ensemble_binary,
            file.path(sdm_output_dir, "ensemble_binary.tif"),
            overwrite = TRUE)

writeRaster(pred_maxent,
            file.path(sdm_output_dir, "pred_maxent.tif"),
            overwrite = TRUE)
writeRaster(pred_rf,
            file.path(sdm_output_dir, "pred_rf.tif"),
            overwrite = TRUE)
if (!is.null(pred_brt)) {
  writeRaster(pred_brt,
              file.path(sdm_output_dir, "pred_brt.tif"),
              overwrite = TRUE)
}
writeRaster(pred_gam,
            file.path(sdm_output_dir, "pred_gam.tif"),
            overwrite = TRUE)
writeRaster(pred_glm,
            file.path(sdm_output_dir, "pred_glm.tif"),
            overwrite = TRUE)

saveRDS(weights, file.path(sdm_output_dir, "ensemble_weights.rds"))
saveRDS(tss_result, file.path(sdm_output_dir, "tss_result.rds"))

cat("All outputs saved to:", sdm_output_dir, "\n")
```

# 11. Ecological Validation

```{r ecological-validation}
# Extract environmental values at predicted suitable locations
suitable_cells <- as.data.frame(ensemble_binary, xy = TRUE, na.rm = TRUE)
suitable_cells <- suitable_cells[as.integer(suitable_cells[[3]]) == 1L, ]
suitable_vect <- vect(suitable_cells[, 1:2], geom = c("x", "y"), crs = "EPSG:4326")
suitable_env <- terra::extract(env_all, suitable_vect)

cat("=== Ecological Validation ===\n\n")

if ("bio5" %in% names(suitable_env)) {
  bio5_range <- range(suitable_env$bio5, na.rm = TRUE)
  cat(sprintf("Max temp warmest month (bio5) in suitable area: %.1f - %.1f C\n",
              bio5_range[1], bio5_range[2]))
  cat(sprintf("  Expected upper limit: ~32-33C (Heat stress threshold)\n"))
  cat(sprintf("  Check: %s\n\n",
              ifelse(bio5_range[2] <= 35, "PASS", "WARNING - exceeds expected limit")))
}

if ("bio6" %in% names(suitable_env)) {
  bio6_range <- range(suitable_env$bio6, na.rm = TRUE)
  cat(sprintf("Min temp coldest month (bio6) in suitable area: %.1f - %.1f C\n",
              bio6_range[1], bio6_range[2]))
  cat(sprintf("  Expected lower limit: ~8C (Developmental threshold)\n"))
  cat(sprintf("  Check: %s\n\n",
              ifelse(bio6_range[1] >= -2, "PASS - within reasonable range",
                     "WARNING - well below expected limit")))
}

if ("bio12" %in% names(suitable_env)) {
  bio12_range <- range(suitable_env$bio12, na.rm = TRUE)
  cat(sprintf("Annual precipitation (bio12) in suitable area: %.0f - %.0f mm\n",
              bio12_range[1], bio12_range[2]))
  cat(sprintf("  Expected: >500 mm (moisture requirement for off-host survival)\n\n"))
}

cat("Geographic extent of predicted suitable habitat:\n")
cat(sprintf("  Latitude: %.1f to %.1f S\n",
            abs(max(suitable_cells$y)), abs(min(suitable_cells$y))))
cat(sprintf("  Longitude: %.1f to %.1f E\n",
            min(suitable_cells$x), max(suitable_cells$x)))
cat("\n")
cat("Expected range (Teo et al. 2021):\n")
cat("  Coastal fringe from north QLD (~15S) to eastern VIC (~38S)\n")
cat("  Predominantly east of the Great Dividing Range\n")
```

## 11.1 Cross-Validation Performance Summary

```{r final-summary}
cat("\n")
cat("===================================================\n")
cat("  FINAL MODEL PERFORMANCE SUMMARY\n")
cat("===================================================\n\n")

print(cv_summary, row.names = FALSE)

cat("\n")
cat("Ensemble weights:\n")
for (i in seq_along(algo_names)) {
  cat(sprintf("  %15s: %.3f\n", algo_names[i], weights[i]))
}
cat(sprintf("\nTSS threshold for binary map: %.3f\n", tss_result$threshold))
cat(sprintf("Number of occurrence records used: %d\n", sum(model_data$presence == 1)))
cat(sprintf("Number of background points used: %d\n", sum(model_data$presence == 0)))
cat(sprintf("Number of environmental predictors: %d\n", length(pred_cols)))
cat(sprintf("Predictors: %s\n", paste(pred_cols, collapse = ", ")))
```

# 12. Session Info

```{r session-info}
sessionInfo()
```
